\chapter{Related Work}

This chapter will outline the current state-of-the-art research surrounding carbon-aware (temporal) scheduling, as well as the approach taken for determining that.

\section{Systematic Approach}

We used the following system for finding related work to our topic.
First, two groups of keywords are brainstormed for use in querying academic search engines, one group corresponds to carbon-awareness, and the other deals with computing environments.
The specific keywords used for each group are listed in Table \ref{tab:lit_study_keywords}.

\begin{table}[h!]
\centering
\begin{tabular}{|c|p{7cm}|}
\hline
    Group & Keywords \\ \hline
    carbon-awareness & \text{energy efficiency}, \text{energy consumption}, \text{carbon impact} \\ \hline
    \text{computing environments} & \text{datacenter}, \text{load balancing}, \text{scheduling}, \text{job shop}, \text{job management}, \text{compute cluster}, \text{hpc}, \text{placement}, \text{cloud} \\ \hline
\end{tabular}
\caption{List of keywords for each group used in the literature study}
\label{tab:lit_study_keywords}
\end{table}

Using these two groups, we then created Google Scholar queries via the cross-product between them. 
Use of the double-quotation feature restricts the results further.
For each query, we then read the abstracts of, on average, the first 5 results, depending on if their titles seemed subjectively fit. 

These are then entered into a spreadsheet: for each query, 5 paper titles. Additionally, we further explored papers through \emph{connected papers}\webcite{web_connectedpapers} or looked up individual authors on a subjective basis. 
The papers from the HotCarbon Workshops\webcite{web_hotcarbon} also proved to be related.

We then sort each paper into one of the following categories:

\begin{enumerate}
    \item Green, meaning that they seem very connected and are good first entries into the topic
    \item Orange indicates they are somehow connected to the paper and might be read at a later date
    \item Red, the paper is either irrelevant or has some other flaw. These will not be used again in the course of our work
\end{enumerate}

\paragraph{Results}

The results are exported as \verb|literature_study.csv| in the appendix\ref{appendix:literature_review_results}, according to its evaluation using the \verb|literature_study_evaluation| Jupyter Notebook, 145 abstract were read. 
Using the above categorization, 99 are marked red, 31 orange, and 15 green.

Overall, through this approach, a lot of unrelated papers were found.
Nevertheless, with the green ones, the current state of carbon-aware scheduling can be outlined.
Out of those, the following are of particular interest.

\section{State of the Art} \label{sec:state_of_the_art}

\paragraph{Testbeds and Simulations}
There are multiple implementations in recent literature. Wiesner et al. \cite{wiesner_lets_2021} use a simulation approach to examine temporal shifting via their \emph{WaitAWhile} algorithm. Their workload model consists of known length jobs with constant power, explicitly ruling out resumption costs. 
Jobs can then either use suspend \& resume or not, both scenarios are evaluated. 
These are then tested under the assumption of different job deadlines, meaning that each job has to be completed by a certain timeframe, and also different regions of the world.
Their main takeaways are that increased deadlines lead to reduced carbon emissions, but that this effect also has diminishing returns. 
They also deduce that regions such as California, with high amounts of solar power, have a higher potential for carbon savings in comparison to nuclear-heavy regions such as France.

Another closely related paper was made by Sukprasert et al. \cite{sukprasert_limitations_2024}
They add on the above workload model by incorporating CPU requirements and differing arrival times for jobs. In the previous paper, job arrivals were assumed to be spread out evenly. Here, they use three real-world traces resulting in a spread of lengths, requirements, and arrivals. 
Due to the latter, weekly observations on carbon emission curves play into the result as well. For example the circumstance that power demand is lessened on weekends.
Jobs are scheduled on \emph{spot} instances (cheap VMs that seek to increase cloud utilization), \emph{on-demand} instances (short-notices VMs that are thus more expensive) or \emph{pre-bought} VMs (medium cost, but may not get utilized).
The paper then discusses balancing performance as well as carbon- and dollar costs. 

The two mentioned simulations assume perfect knowledge for near-future carbon emissions and schedule jobs in foresight. Hanafy et al. \cite{lechowicz_online_2023} use an algorithmic approach based on the \emph{Online Pause and Resume Problem (OPR)}. 
Suspend \& resume scheduling is reducible to OPR. The Problem involves deciding to buy a resource for each time slot or not to. 
Switching between these decisions (suspending or resuming a workload) carries a cost. In our approach, resuming or starting a job carries a time cost, which in turn results in emissions.

There is another paper building upon WaitAWhile by Hanafy et al. \cite{hanafy_war_2023}. Their goal is to examine the differences between energy efficiency and carbon efficiency. In one scenario, they add different overheads for resuming a job according to WaitAWhile. 
Under their model, carbon-efficiency still improved with increasing deadlines, but they assumed the scheduling to be independent of the overhead.
In our work, the scheduler will take overhead into account.

With many testbed implementations in literature, Wiesner et al. \cite{wiesner_vessim_2024} aim to generalize one for comparability. Their \emph{Vessim} is a simulation framework for carbon-aware testing aimed at extensibility and software architecture.

\paragraph{Slurm Schedulers}

Of the analyzed papers, the one made by Goiri et al. \cite{inigo_goiri_greenslot_2011} seems to be among first papers to deal with carbon-aware scheduling by implementing it as a \emph{Slurm} plugin (See section \ref{subsec:slurm_plugin} for further information on Slurm and such plugins) called \emph{GreenSlot}.
In contrast to our scenario, where we try to optimize carbon emissions via the public electricity grid, GreenSlot is about data centers having their own renewable energy production (e.g. via having solar panels on the roof). 
Using weather data, GreenSlot predicts when solar energy production is high, scheduling jobs preferably in those time frames.
Under their workload model, jobs may also have deadlines.
If those deadlines cannot be met using only renewables, \emph{Greenslot} will additionally schedule jobs on high-carbon times, based on electricity cost.

In Section \label{subsec:slurm_plugin}, a plugin approach will be discussed. Springborg et al. \cite{aaen_springborg_automatic_2023} propose an architecture for incorporating Python plugins into Slurm. 
They implement an exemplary energy-efficiency plugin for a single-node cluster environment. 

All of these techniques are then tested under various parameters. Our work will only make use of temporal shifting, and abstract away the other methods of further carbon savings.

\paragraph{Summary}
There are multiple approaches to testbeds for carbon-aware job scheduling. A common theme is to examine job lengths, arrival times, and deadlines for effects on carbon emissions. Overhead from resuming jobs is considered in some prior work but, atleast to our knowledge, none of them use a time-based overhead for scheduling as well. Power heterogeneity was not included in any of the examined papers.