\chapter{Methodology}

- Bisherige Arbeiten hatten die Annahme, das Jobs eine bestimmte länge haben und eine konstante Leistung benötigen.
- Das Stoppen und Resumen von Jobs erzeugte keinen Overhead. 
- Wir wollen zeigen, dass diese Annahmen für ausgewählte workloads nicht ausreihen, beispielsweise für ML trainings, welche QUELLE Prozent der Task in einem Compute Center ausmachen.
- Dazu Messen wir die Leistungsaufnahme eines ML trainings und untersuchen wie sich der Workload bzgl. stop-resume verhält.

\section{Leistungsmessungen}

\begin{itemize}
    \item Warum ist das interessant
    \item Wie habe ich die Messungen ausgeführt (MCP beschreiben, sowie pinpoint als Schnittstelle)
    \item Experimentier-parameter (?), also wodurch versuche ich sicherzustellen, dass meine Messungen auch sinn machen / reproduzierbar sind usw usw.
    \item Wie habe ich das ausgewertet, schöne graphs zeigen
\end

Da wir nun eine Vorstellung haben, wie realistischere Jobs aussehen, könnten wir davon ein Model ableiten:
(Das sieht so aus wie meine .csv Schemas), jetzt könnten wir zeigen, wie sich die Leistungsaufnahme zw. dem Model-Job und dem realen Job unterscheidet
Hier kämen auch die ganzen Fehlerbetrachtungen rein (cross-validation / absoluter Fehler),
auch zeigen, dass das mit stop resume funktioniert.


Modellbeschreibung, welches Modell verfolgen meine Workloads?
Workloads haben stages, begründung via der power measurements an den sample ML workloads
Softwarearchitekturbeschreibung
wie die experiment ausführen / format usw usw.

\section{Annahmen}

\begin{itemize}
    \item Joblängen sind bekannt
    \item Jobs können zeitlich verschoben werden (begründet daraus, dass sie als Batch Jobs submitted werden, andere Jobs werden hierbei nicht betrachtet)
    \item User geben dabei an, wie lange der Job verschoben werden darf
    \item Die carbon curve auf dem electrical grid ist für kurze Zeiträume in der Zukunft bekannt
    \item Die Hardware ist zZ nicht begrenzt. Das war in der related work auch nicht so. Eigentlich wäre es spannend sich das anzuschauen, allerdings sind die bisherigen Scheduler halt darauf garnicht gemünzt, da werden alle Jobs unabh. voneinander gescheduled. Man könnte das via publicCloud argumentieren, allerdings wäre das questionable, in wie fern der scorelab trace benutzt werden kann (da das ja auf in einem lokalem datacenter läuft)
    \item TODO: Joblängen sollten dem Scheduler nicht bekannt sein. Die Workloads aus GAIA werden allerdings so gescheduled als ob man perfekte Knowledge hat. Das reicht zwar für ein upper bound an carbon savings, ist aber nicht sehr realistisch.  
    \item Jobs haben auch einen dynamischen Energieverbrauch, der sich über die Zeit hin ändert. Diese Funktion ist nur von de Zeit abh. und wird vom Nutzer definiert.
    \item Jobs werden immer completen, Fehler / Nutzercancellations werden ausgeklammert.
\end{itemize}

\section{Datengrundlagen}

\begin{itemize}
    \item Welche Traces gibt es, wodurch werden die characterisiert? (Länge, Anzahl, etc, etc) Vllt. kann man hier nen coolen vergleich erstellen, Auch könnte man ein paar Sätze darüber schreiben, wie die bisher in GAIA aufgenommen wurden.
    \item Wie den scorelab trace benutzen und übersetzen? Gerne auf ner halben Seite aufschlüsseln, was die einzelnen Attribute aus sacct bedeuten.
    \item Ansonsten kann man noch die dynamic ernergy sachen als Datenquelle auflisten, bzw. das mini experiment mit fmnist und roberta 
\end{itemize}

\section{Programmbeschreibung?}

\begin{itemize}
    \item Architektur, die wird sich nicht besonders von dem bisherigem GAIA unterscheiden, cool wenn ich da noch ne web UI oder ähnliches hätte
    \item Man könnte noch zeigen, welche Auswertungen jetzt möglich sind
\end{itemize}